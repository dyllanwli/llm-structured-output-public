{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet  langchain langchain-openai faiss-cpu tiktoken datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "sys.path.append(os.path.dirname(current_dir))\n",
    "\n",
    "from utils import setup_api_key\n",
    "\n",
    "setup_api_key(file_path='../../config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "def get_model_id(model_type, run_name, project_name, checkpoint_id):\n",
    "    return os.path.join(model_type, \"model_output\", project_name, run_name, checkpoint_id)\n",
    "\n",
    "project_config = {\n",
    "    \"survey-json\": {\n",
    "        \"project_name\": \"survey-json-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/survey_json_datasets_instruction_train\",\n",
    "        \"test_dataset_path\": \"../datasets/survey_json_datasets_instruction_test\",\n",
    "    },\n",
    "    \"schema\": {\n",
    "        \"project_name\": \"schema-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/schema_datasets/schema_data_train\",\n",
    "        \"test_dataset_path\": \"../datasets/schema_datasets/schema_data_test\"\n",
    "    },\n",
    "    \"paraloq\": {\n",
    "        \"project_name\": \"paraloq-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/paraloq/paraloq_data_train\",\n",
    "        \"test_dataset_path\": \"../datasets/paraloq/paraloq_data_test\"\n",
    "    },\n",
    "    \"nous\": {\n",
    "        \"project_name\": \"nous-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/nous/nous_data_train\",\n",
    "        \"test_dataset_path\": \"../datasets/nous/nous_data_test\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def load_project(project=\"schema\"):\n",
    "    test_dataset = load_from_disk(project_config[project][\"test_dataset_path\"])\n",
    "    train_dataset = load_from_disk(project_config[project][\"train_dataset_path\"])\n",
    "    return test_dataset, train_dataset\n",
    "\n",
    "def run(project = \"schema\"):\n",
    "    test_dataset, train_dataset = load_project(project=project)\n",
    "    document_size = 10\n",
    "\n",
    "    examples = []\n",
    "    for data in train_dataset:\n",
    "        instruction, response = data[\"text\"].split(\"[/INST]\")\n",
    "        instruction = instruction.replace(\"<s>[INST]\", \"\").strip()\n",
    "        document_size -= 1\n",
    "        examples.append({\"instruction\": instruction, \"response\": response})\n",
    "        if document_size == 0:\n",
    "            break\n",
    "\n",
    "    task = \"\"\n",
    "    if project == \"schema\":\n",
    "        task = \"Convert the raw data to ld+json format.\"\n",
    "    elif project == \"survey-json\":\n",
    "        task = \"Convert the question list to survey json.\"\n",
    "    elif project == \"paraloq\":\n",
    "        task = \"Generate the structured response for the given query.\"\n",
    "    elif project == \"nous\":\n",
    "        task = \"Generate the structured response for the given query.\"\n",
    "\n",
    "    documents = []\n",
    "    for i, example in enumerate(examples):\n",
    "        documents.append(f\"Example {i+1}:\\nInstruction: {example['instruction']}\\nResponse: {example['response']}\\n\\n\")\n",
    "\n",
    "    test_data = []\n",
    "\n",
    "    for data in tqdm(test_dataset):\n",
    "        instruction, response = data[\"text\"].split(\"[/INST]\")\n",
    "        instruction = instruction.replace(\"<s>[INST]\", \"\").strip()\n",
    "        prompt = f\"{task}\\nInstruction: {instruction}\\nResponse:\"\n",
    "        test_data.append({\"prompt\": prompt, \"response\": response})\n",
    "        \n",
    "    vectorstore = FAISS.from_texts(\n",
    "        documents, embedding=OpenAIEmbeddings()\n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    template = \"\"\"Response based on the following context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    chain_model = ChatOpenAI(temperature=0)\n",
    "\n",
    "    chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | chain_model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    generated_responses = []\n",
    "    actual_responses = []\n",
    "\n",
    "    for data in tqdm(test_data):\n",
    "        response = chain.invoke(data['prompt'])\n",
    "        generated_responses.append(response)\n",
    "        actual_responses.append(data['response'].strip())\n",
    "\n",
    "    export_date = {\n",
    "        \"generated_responses\": generated_responses,\n",
    "        \"actual_responses\": actual_responses\n",
    "    }\n",
    "\n",
    "    # write to json file\n",
    "    with open(f'./{project}_instruction_generation.json', 'w') as f:\n",
    "        json.dump(export_date, f)\n",
    "\n",
    "    # load json file \n",
    "    with open(f'./{project}_instruction_generation.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = [\"schema\", \"paraloq\", \"nous\"]\n",
    "for project in run_list:\n",
    "    run(project=project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model = ChatOpenAI(temperature=0)\n",
    "class Metric(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Metric)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | chain_model | parser\n",
    "for pred, ground_truth in zip(preds, ground_truths):\n",
    "    metric_query = f\"\"\n",
    "    chain.invoke({\"query\": metric_query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
