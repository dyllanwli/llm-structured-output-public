{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "sys.path.append(os.path.dirname(current_dir))\n",
    "\n",
    "from utils import setup_api_key\n",
    "\n",
    "setup_api_key(file_path='../../config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded datasets with num examples:  485\n",
      "Num tokens:  129827\n",
      "Max num tokens:  2008\n",
      "Loaded datasets with num examples:  484\n",
      "Num tokens:  567383\n",
      "Max num tokens:  2946\n",
      "Loaded datasets with num examples:  100\n",
      "Num tokens:  30570\n",
      "Max num tokens:  670\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "def get_model_id(model_type, run_name, project_name, checkpoint_id):\n",
    "    return os.path.join(\n",
    "        model_type, \"model_output\", project_name, run_name, checkpoint_id\n",
    "    )\n",
    "\n",
    "\n",
    "project_config = {\n",
    "    \"survey-json\": {\n",
    "        \"project_name\": \"survey-json-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/survey_json_datasets_instruction_train\",\n",
    "        \"test_dataset_path\": \"../datasets/survey_json_datasets_instruction_test\",\n",
    "    },\n",
    "    \"schema\": {\n",
    "        \"project_name\": \"schema-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/schema_datasets/schema_data_train\",\n",
    "        \"test_dataset_path\": \"../datasets/schema_datasets/schema_data_test\",\n",
    "    },\n",
    "    \"paraloq\": {\n",
    "        \"project_name\": \"paraloq-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/paraloq/paraloq_data_train\",\n",
    "        \"test_dataset_path\": \"../datasets/paraloq/paraloq_data_test\",\n",
    "    },\n",
    "    \"nous\": {\n",
    "        \"project_name\": \"nous-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/nous/nous_data_train\",\n",
    "        \"test_dataset_path\": \"../datasets/nous/nous_data_test\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def load_project(project=\"schema\"):\n",
    "    train = load_from_disk(project_config[project][\"train_dataset_path\"])\n",
    "    test = load_from_disk(project_config[project][\"test_dataset_path\"])\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def calculate_token(dataset):\n",
    "\n",
    "    def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "        \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "        return num_tokens\n",
    "    \n",
    "    text = \"\"\n",
    "    max_text = \"\"\n",
    "    for example in dataset:\n",
    "        text += example[\"text\"]\n",
    "        max_text = max(max_text, example[\"text\"], key=len)\n",
    "    num_tokens = num_tokens_from_string(text)\n",
    "    max_num_tokens = num_tokens_from_string(max_text)\n",
    "    return num_tokens, max_num_tokens\n",
    "\n",
    "\n",
    "def run(project=\"schema\"):\n",
    "    train, test = load_project(project=project)\n",
    "    train_tokens, max_train_tokens = calculate_token(train)\n",
    "    test_tokens, max_test_tokens = calculate_token(test)\n",
    "    num_tokens = max(train_tokens, test_tokens)\n",
    "    print(\"Loaded datasets with num examples: \", train.num_rows + test.num_rows)\n",
    "    print(\"Num tokens: \", num_tokens)\n",
    "    print(\"Max num tokens: \", max(max_train_tokens, max_test_tokens))\n",
    "    \n",
    "    \n",
    "\n",
    "run_list = [\"schema\", \"paraloq\", \"nous\"]\n",
    "for project in run_list:\n",
    "    run(project=project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] You are a helpful assistant that answers in JSON. Here's the json schema you must adhere to:\n",
      "<schema>\n",
      "{'CustomerVehicleServiceHistory': {'type': 'object', 'properties': {'customerID': {'title': 'Customer ID', 'type': 'string'}, 'vehicleID': {'title': 'Vehicle ID', 'type': 'string'}, 'serviceRecords': {'title': 'Service Records', 'type': 'array', 'items': {'type': 'object', 'properties': {'serviceDate': {'title': 'Service Date', 'type': 'string', 'format': 'date'}, 'description': {'title': 'Description', 'type': 'string'}, 'cost': {'title': 'Cost', 'type': 'number'}}, 'required': ['serviceDate', 'description', 'cost']}}, 'totalSpent': {'title': 'Total Spent', 'type': 'number'}}, 'required': ['customerID', 'vehicleID', 'serviceRecords', 'totalSpent']}}\n",
      "</schema>\n",
      "I recently purchased a used car and I'd like to have a complete service history report generated for my vehicle. The vehicle is a 2015 Toyota Camry with the VIN number 4T1BF1FK5FU033209. I am the new owner and my customer ID is CU789456. The previous owner provided me with the service records which include the following: 1) Service Date: 2016-05-10, Description: Oil Change, Cost: $75.00; 2) Service Date: 2017-04-22, Description: Brake Pad Replacement, Cost: $150.00; 3) Service Date: 2018-03-15, Description: Battery Replacement, Cost: $100.00; 4) Service Date: 2019-06-30, Description: Tire Rotation, Cost: $50.00; 5) Service Date: 2020-07-18, Description: Air Filter Replacement, Cost: $45.00. The total amount spent on these services is $420.00. Please respond with a valid json object. [/INST] {\"customerID\": \"CU789456\", \"vehicleID\": \"4T1BF1FK5FU033209\", \"serviceRecords\": [{\"serviceDate\": \"2016-05-10\", \"description\": \"Oil Change\", \"cost\": 75.0}, {\"serviceDate\": \"2017-04-22\", \"description\": \"Brake Pad Replacement\", \"cost\": 150.0}, {\"serviceDate\": \"2018-03-15\", \"description\": \"Battery Replacement\", \"cost\": 100.0}, {\"serviceDate\": \"2019-06-30\", \"description\": \"Tire Rotation\", \"cost\": 50.0}, {\"serviceDate\": \"2020-07-18\", \"description\": \"Air Filter Replacement\", \"cost\": 45.0}], \"totalSpent\": 420.0}\n"
     ]
    }
   ],
   "source": [
    "train, test = load_project(project=\"nous\")\n",
    "print(train[23]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
