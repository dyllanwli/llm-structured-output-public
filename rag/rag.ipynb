{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "sys.path.append(os.path.dirname(current_dir))\n",
    "\n",
    "from utils import setup_api_key\n",
    "\n",
    "setup_api_key(file_path='../../config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "\n",
    "            \n",
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "def get_model_id(model_type, run_name, project_name, checkpoint_id):\n",
    "    return os.path.join(model_type, \"model_output\", project_name, run_name, checkpoint_id)\n",
    "\n",
    "project_config = {\n",
    "    \"survey-json\": {\n",
    "        \"project_name\": \"survey-json-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/survey_json_datasets_instruction_train\",\n",
    "        \"test_dataset_path\": \"../datasets/survey_json_datasets_instruction_test\",\n",
    "    },\n",
    "    \"schema\": {\n",
    "        \"project_name\": \"schema-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/schema_datasets/schema_data_train\",\n",
    "        \"test_dataset_path\": \"../datasets/schema_datasets/schema_data_test\"\n",
    "    },\n",
    "    \"paraloq\": {\n",
    "        \"project_name\": \"paraloq-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/paraloq/paraloq_data_train\",\n",
    "        \"test_dataset_path\": \"../datasets/paraloq/paraloq_data_test\"\n",
    "    },\n",
    "    \"nous\": {\n",
    "        \"project_name\": \"nous-model-inst\",\n",
    "        \"train_dataset_path\": \"../datasets/nous/nous_data_train\",\n",
    "        \"test_dataset_path\": \"../datasets/nous/nous_data_test\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def load_project(project=\"schema\"):\n",
    "    test_dataset = load_from_disk(project_config[project][\"test_dataset_path\"])\n",
    "    train_dataset = load_from_disk(project_config[project][\"train_dataset_path\"])\n",
    "    return test_dataset, train_dataset\n",
    "\n",
    "def get_result(project= \"schema\"):\n",
    "    test_dataset, train_dataset = load_project(project=project)\n",
    "    example_size = 3\n",
    "\n",
    "    examples = []\n",
    "    for data in train_dataset:\n",
    "        instruction, response = data[\"text\"].split(\"[/INST]\")\n",
    "        instruction = instruction.replace(\"<s>[INST]\", \"\").strip()\n",
    "        if project == \"schema\":\n",
    "            instruction = instruction.replace(\"Convert the raw data to ld+json format.\", \"\").strip()\n",
    "        example_size -= 1\n",
    "        examples.append({\"instruction\": instruction, \"response\": response})\n",
    "        if example_size == 0:\n",
    "            break\n",
    "\n",
    "    task = \"\"\n",
    "    if project == \"schema\":\n",
    "        task = \"Convert the raw data to ld+json format.\"\n",
    "    elif project == \"survey-json\":\n",
    "        task = \"Convert the question list to survey json.\"\n",
    "    elif project == \"paraloq\":\n",
    "        task = \"Generate the structured response for the given query.\"\n",
    "    elif project == \"nous\":\n",
    "        task = \"Generate the structured response for the given query.\"\n",
    "        \n",
    "    pre_prompt = f\"Given few examples of instructions and responses from the training dataset. The task is to generate a response for the given instruction. {task}\\n\\n\"\n",
    "\n",
    "    for i, example in enumerate(examples):\n",
    "        pre_prompt += f\"Example {i+1}:\\nInstruction: {example['instruction']}\\nResponse: {example['response']}\\n\\n\"\n",
    "\n",
    "    test_data = []\n",
    "\n",
    "    for data in tqdm(test_dataset):\n",
    "        instruction, response = data[\"text\"].split(\"[/INST]\")\n",
    "        instruction = instruction.replace(\"<s>[INST]\", \"\").strip()\n",
    "        prompt = f\"{pre_prompt}\\nInstruction: {instruction}\\nResponse:\"\n",
    "        test_data.append({\"prompt\": prompt, \"response\": response})\n",
    "\n",
    "    chain_model = ChatOpenAI(temperature=0)\n",
    "\n",
    "    generated_responses = []\n",
    "    actual_responses = []\n",
    "\n",
    "    for data in tqdm(test_data):\n",
    "        response = chain_model.invoke(data['prompt'])\n",
    "        generated_responses.append(response.content)\n",
    "        actual_responses.append(data['response'].strip())\n",
    "\n",
    "    export_date = {\n",
    "        \"generated_responses\": generated_responses,\n",
    "        \"actual_responses\": actual_responses\n",
    "    }\n",
    "\n",
    "    # write to json file\n",
    "    with open(f'./{project}_instruction_generation.json', 'w') as f:\n",
    "        json.dump(export_date, f)\n",
    "\n",
    "    return data\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json(sample):\n",
    "    match = re.search(r'<script type=\"application/ld\\+json\">\\s*(.*?)\\s*</script>', sample, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        return json.loads(json_str)\n",
    "    else:\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
